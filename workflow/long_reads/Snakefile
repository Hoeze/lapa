def file_acc(wildcards):
    df = pd.read_csv(config['lrgasp']['config'], sep='\t')
    df = df[
        (df['file_contents'] == 'reads') &
        (df['sample'] == wildcards['sample']) &
        (df['platform'] == wildcards['platform']) &
        (df['library_prep'] == wildcards['library_prep']) 
    ]
    return df['file_acc'].tolist()


def long_reads_bam(wildcards):
    return expand(config['encode']['bam'], encode_id=file_acc(wildcards))


rule lapa_long_reads_samples:
    input:
        bams = long_reads_bam
    params:
        encode_id = file_acc
    output:
        csv = config['lapa']['samples']
    run:
        with open(output['csv'], 'w') as f:
            f.write('sample,path\n')
            for encode_id, bam_file in zip(params['encode_id'], input['bams']):
                f.write(f'{encode_id},{bam_file}\n')


rule lapa_longreads:
    input:
        samples = config['lapa']['samples'],
        fasta = fasta,
        gtf = gtf,
        chrom_sizes = chrom_sizes
    threads: 1
    resources:
        mem_gb = 16
    output:
        directory(config['lapa']['lapa_dir'])
    shell:
        "lapa \
        --alignment {input.samples} \
        --fasta {input.fasta} \
        --annotation {input.gtf} \
        --chrom_sizes {input.chrom_sizes} \
        --counting_method {wildcards.counting} \
        --output_dir {output}"


pb_library_prep = ['cDNA', 'CapTrap']
ont_library_prep = ['cDNA', 'dRNA', 'CapTrap', 'R2C2']


rule all_long_rnaseq:
    input:
        expand(config['lapa']['lapa_dir'], sample='WTC11', platform=['PacBio'],
               counting=['end', 'tail'], library_prep=pb_library_prep),
        expand(config['lapa']['lapa_dir'], sample='WTC11', platform=['ONT'],
               counting=['end', 'tail'], library_prep=ont_library_prep)
